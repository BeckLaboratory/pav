#!/usr/bin/env python3

import argparse
import logging
import os
import sys

# Init logging
logger_root = logging.getLogger()
logger_root.setLevel(logging.CRITICAL)
handler = logging.StreamHandler(sys.stdout)
handler.setFormatter(logging.Formatter('%(name)s (%(levelname)s) - %(message)s'))
logger_root.addHandler(handler)

logger = logging.getLogger('lctrain')
logger.setLevel(logging.WARNING)


#
# Definitions
#

def parse_arguments(argv=None):
    """
    Parse command-line arguments.

    :param argv: Array of command-line arguments or None to read from sys.argv.
    """

    if argv is None:
        argv = sys.argv[1:]

    epilog = \
"""
This pipeline runs in four stages: init (locates input files), features (generates matrices for training), train (model
training), and eval (model evaluation), and the pipeline automatically starts at the first incomplete stage. To setup,
create a symbolic link to "files/lcmodel/train.py" from a PAV pipeline directory in a clean working directory, and the
script will locate PAV dependencies is requires. For detailed information, see
"files/lcmodel/LC_MODEL.md" in the PAV pipeline directory for details.
"""

    parser = argparse.ArgumentParser(
        description='Train a model to recognize low-confidence alignment records.',
        epilog=epilog
    )

    parser.add_argument('-l', '--log-level',
                        default='INFO', type=str.upper,
                        choices=['DEBUG', 'INFO', 'WARNING', 'ERROR', 'CRITICAL'],
                        help='Logging level for the training code. Logging levels are not case sensitive.')

    parser.add_argument('-L', '--root-log-level',
                        default='CRITICAL', type=str.upper,
                        choices=['DEBUG', 'INFO', 'WARNING', 'ERROR', 'CRITICAL'],
                        help='Root logging level. Will show messages generated by libraries the training script uses. '
                             'Logging levels are not case sensitive.')

    parser.add_argument('-w', '--workdir',
                        default='workdir', type=str,
                         help='Directory where output files are written.')

    parser.add_argument('-g', '--stage-start',
                        default=None, type=str.lower,
                        choices=['init', 'features', 'cv', 'train', 'eval'],
                        help='Force pipeline stage to restart at a specific stage. Pipeline will fail if a previous '
                             'stage is not complete. By default, the pipeline will start at the first incomplete stage.')

    parser.add_argument('-G', '--stage-end',
                        default='eval', type=str.lower,
                        choices=['init', 'features', 'cv', 'train', 'eval'],
                        help='End on this pipeline stage.')

    parser.add_argument('-n', '--pretend',
                        default=False, action='store_true',
                        help='Show what would be done, but do not run the pipeline. Must have at least INFO logging'
                             '(-l) to see what would run.')

    parser.add_argument('--cv', default=False, action='store_true',
                        help='Run cross-validation to test model performance without using the reserved test set.')

    parser.add_argument('config', nargs='+', type=str,
                        help='JSON configuration file(s) defining how the model should be trained. If multiple files '
                             'are given, they are concatenated together at the highest-level key.')

    parser.add_argument('-o', '--outdir',
                        default='.', type=str,
                        help='Directory where output files are written. A new directory with the model\'s name is '
                             'created within this directory and the final model is written to it.'
                        )

    args = parser.parse_args(argv)

    # Implicit CV if start or end stage is CV
    if args.stage_start == 'cv' or args.stage_end == 'cv':
        args.cv = True

    # Return arguments
    return args


#
# Main
#

if __name__ == '__main__':
    try:
        # Process command-line arguments and initialize
        args = parse_arguments()

        logger.setLevel(logging.getLevelName(args.log_level))
        logger_root.setLevel(logging.getLevelName(args.root_log_level))

        logger.debug('LC training script starting')

        # Set library paths
        LCTRAIN_DIR = os.path.dirname(os.path.realpath(__file__))

        PAV_DIR = LCTRAIN_DIR

        for i in range(2):
            PAV_DIR = os.path.dirname(PAV_DIR)

        logger.debug('Located LC train source directory: %s', LCTRAIN_DIR)
        logger.debug('Located PAV pipeline directory: %s', PAV_DIR)

        if not os.path.isdir(os.path.join(LCTRAIN_DIR, 'lctrain')):
            raise RuntimeError(f'Cannot locate the "lctrain" library directory relative to this script. To run this script, create a symbolic link to "files/lcmodel/train.py" in the PAV pipeline directory to a this working directory, and the script will use that link to locate dependencies. Failed to locate "lctrain" in "{LCTRAIN_DIR}"')

        if not os.path.isdir(os.path.join(PAV_DIR, 'pavlib')):
            raise RuntimeError(f'Cannot locate the "pavlib" library directory relative to this script. To run this script, create a symbolic link to "files/lcmodel/train.py" in the PAV pipeline directory to a this working directory, and the script will use that link to locate dependencies. Failed to locate "pavlib" in "{PAV_DIR}"')

        if not os.path.isdir(os.path.join(PAV_DIR, 'dep', 'svpop', 'svpoplib')):
            raise RuntimeError(f'Cannot locate PAV dependencies in the PAV run directory (dep/svpop), was PAV cloned with submodules (i.e. "git clone --recursive ...")?')

        sys.path.append(PAV_DIR)
        sys.path.append(os.path.join(PAV_DIR, 'dep'))
        sys.path.append(os.path.join(PAV_DIR, 'dep', 'svpop'))
        sys.path.append(os.path.join(PAV_DIR, 'dep', 'svpop', 'dep'))
        sys.path.append(os.path.join(PAV_DIR, 'dep', 'svpop', 'dep', 'ply'))
        sys.path.append(LCTRAIN_DIR)

        logger.debug('Loading library dependencies')

        import pavlib
        import lctrain

        # Read config
        lctrain_config = lctrain.util.read_lctrain_config(args.config)

        # Determine steps to run
        stage_order = {
            'init': 0,
            'features': 1,
            'cv': 2,
            'train': 3,
            'eval': 4
        }

        force = False

        if args.stage_start is not None:
            stage_start = stage_order[args.stage_start]
            force = True
        else:
            stage_start = 0

        stage_end = stage_order[args.stage_end]

        stage_list = [
            lctrain.stage.StageInit(lctrain_config, args.workdir, args.outdir),
            lctrain.stage.StageFeatures(lctrain_config, args.workdir, args.outdir),
            lctrain.stage.StageCV(lctrain_config, args.workdir, args.outdir),
            lctrain.stage.StageTrain(lctrain_config, args.workdir, args.outdir),
            lctrain.stage.StageEval(lctrain_config, args.workdir, args.outdir)
        ]

        # Run stages
        for i in range(0, len(stage_list)):

            # Stop if stage is past the end stage (-G)
            if i > stage_end:
                logger.debug('Skipping end stages (-G option): %s', stage_list[i].stage_name)
                continue

            # Check previous stages
            if i < stage_start:
                if stage_list[i].run(False, True, args):
                    raise RuntimeError(f'Cannot start execution at stage "{stage_list[stage_start].stage_name}": Previous stage "{stage_list[i].stage_name}" is incomplete')

                continue

            # Run stage
            pretend = args.pretend

            logger.info('Running stage: %s%s', stage_list[i].stage_name, (' (forced)' if force else ''))

            stage_list[i].run(force, pretend, args)

    finally:
        # Ensure logs are flushed
        logging.shutdown()
